# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1irzkP7lKmeQUQPbcZaCGK3KmLQvkybJ7

# **Import Libraries**
"""

!pip install scikit-learn==1.3.2

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectKBest, chi2, f_classif
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score

"""# **Download Dataset**"""

data_path = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/refs/heads/master/data/Telco-Customer-Churn.csv'
df = pd.read_csv(data_path)

"""# **Data Understanding**

Check data summary
"""

# shape dari data
df.shape

# 5 baris pertama data
df.head().T

df.info()

# menghitung missing values
df.isna().sum()

# deskripsi statistik data
df.describe(include='all').T

print(f'banyaknya data yang terduplikasi: {df.duplicated().sum()}')

"""Ada kemungkinan salah penulisan atau double writting dengan makna yang sama, seperti: yes, Yess, Yes, sehingga perlu memastikan unique values yang ada."""

# cek incorrect values
for col in df.select_dtypes(include=['object']).columns:
    print(df[col].value_counts(dropna=False))
    print("-" * 20)

"""## **Insights**:

#### **1. Data Types & Non-null Counts:**
* Dataset berisi **7043** baris dan **21** kolom.
* **Data types**: Terdapat 18 kolom dengan tipe data `object`, 2 kolom dengan tipe data `int64`, dan 1 kolom dengan tipe data `float64`.
     * **Numerical Features**: Features yang termasuk adalah `SeniorCitizen`, `tenure` dan `MonthlyCharges`.
     * **Categorical Features**: Features yang termasuk adalah `Partner`, `gender`, etc.

#### **2. Summary Statistics:**
* **Categorical Data**:
     * `customerID` memiliki unique values terbanyak.
     * Untuk kolom-kolom lain memiliki data unique minimal 2 dan maksimalnya 4.
     * `TotalCharges` tipe datanya harus diubah sehingga summary statistics-nya bisa terbaca.
* **Numerical Data**:
     * `tenure` memiliki rata-rata sebesar `32.37` atau setara 32 bulan dari range berlangganan `0` hingga `72` bulan. Rata-rata tersebut menunjukkan sebagian besar pelanggan berhenti di pertengahan bulan, hal ini bisa dijadikan indikator adanya ketidakpuasan terhadap layanan yang diberikan.
     * `MonthlyCharges` memiliki rata-rata sebesar `$64.76` dengan standar deviasi sebesar `$30.09`, mengindikasikan variasi harga tagihan bulanan antar pelanggan yang beragam. Rentang transaksi bulanan minimal `$18.25` dan maksimal `$118.75`, menunjukkan perbedaan yang sangat signifikan dalam transaksi dan terdapat potensi untuk memaksimalkan penggunaan layanan yang disediakan oleh perusahaan kepada pelanggan.
     

#### **3. Missing Values Summary:**
* Untuk saat ini tidak terdapat kolom yang berisi missing values.

#### **4. Duplicate & Unique Values Summary:**
* Dari `df.duplicated()`, unique values, dan `df.head()` tidak terlihat ada data yang terduplikasi.
* `customerID` tidak diperlukan untuk proses modeling.
* `TotalCharges` tidak tepat menggunakan tipe data object.
* Tidak ada unique values yang berasal dari salah penulisan atau double writting.
* Terdapat data imbalance dalam target (churn), yaitu `No` memiliki jumlah `5174` dan `Yes` jumlahnya `1869`.

#### **Masalah yang Bisa Diselesaikan:**
* Penulisan nama kolom tidak konsisten, seperti: lower case, diawali huruf kecil/kapital, dan camel case.
* Penulisan kapitalisasi data dalam setiap baris tidak konsisten dan nama kolom juga, sehingga bisa diubah menjadi lower case semua.
* Kolom `SeniorCitizen` berisi data kategorikal apakah seseorang merupakan warga lanjut usia atau tidak dan bukan data untuk perhitungan matematis meskipun bentuk datanya 0 dan 1, jadi tipe datanya bisa diubah dari `int64` menjadi `category`.
* Kolom `TotalCharges` berisi data numerik kontinu sehingga data type-nya perlu diubah, dari `object` menjadi `float64`.
* Perlu dilakukan categorical encoding untuk data-data kategorik.
* Melakukan feature selection daripada menggunakan semua kolom yang ada, contohnya seperti men-drop kolom `customerID`.
* Untuk mengatasi imbalance dataset, pertama-tama dilakukan train-test split untuk memisahkan data training dan testing. Setelah itu, oversampling atau resampling diterapkan pada training set menggunakan teknik SMOTE (Synthetic Minority Over-sampling Technique) agar data menjadi seimbang atau balance selama proses pelatihan model, tanpa mengubah distribusi data pada testing set.

# **Data Cleaning**

#### **Column Renaming & Data Consistency**

Penamaan kolom tidak konsisten sehingga perlu diubah agar konsisten dan sesuai standar.
"""

df.columns = df.columns.str.lower()

"""Data dalam setiap baris memiliki format penulisan yang tidak konsisten sehingga perlu diubah juga."""

categorical_columns = list(df.columns[df.dtypes == 'object'])

for col in categorical_columns:
     df[col] = df[col].str.lower()

"""#### **Correcting Data Type**

Mengubah tipe data yang tidak sesuai dalam setiap kolom di dataset.
"""

df.seniorcitizen = df.seniorcitizen.astype('category')

"""**Insight**:
* Kolom `seniorcitizen` meskipun datanya berupa angka atau numerik yaitu 0 dan 1, tetapi kolom ini berisi data kategorik nomina yang menjelaskan apakah seorang pelanggan lansia atau tidak sehingga datanya diubah dari `int64` menjadi `category`.
"""

df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')

"""**Insights:**
* Mengubah tipe data object menjadi numerik yang sesuai, dalam konteks kolom ini maka tipe data berubah dari `object` menjadi `float64`.
* `errors='coerce'` membuat nilai yang tidak valid atau tidak dapat diubah ke tipe data numerik akan otomatis digantikan dengan `NaN`.
* Sebelumnya missing values ada 0, sebagai akibat menggunakan parameter `errors='coerce'` maka saat ini akan ada kemungkinan adanya missing values di kolom `totalcharges`.

#### **Handling Missing Values**

menangani missing values
"""

df.isna().sum()

df[df.totalcharges.isna()].T

missing_ratio = (df['totalcharges'].isna().sum() / len(df)) * 100
print(f"Missing ratio: {missing_ratio:.2f}%")

"""**Insights**:
* Terdapat missing values di kolom `totalcharges` sebanyak 11.
* Terlihat data yang memiliki missing values bernilai `no` di kolom `churn` yang artinya pelanggan tidak memiliki kecenderungan atau karakteristik untuk berhenti.
* Meskipun pelanggan tidak churn, untuk menentukan langkah selanjutnya (di-drop atau dipertahankan), perlu memperhatikan beberapa hal:
     * Kolom `monthlycharges` sudah berisi harga tagihan bulanan.
     * Namun, semua kolom `tenure` berisi angka `0`, hal ini mengindikasikan bahwa 11 orang ini adalah pelanggan baru.
     * Data dari pelanggan baru tidak memiliki kontribusi yang signifikan dalam model dan belum memiliki pola historis yang cukup atau diperlukan. Selain itu, pelanggan baru saat pertama kali berlangganan atau bulan ke-0 mungkin belum mengalami masalah yang sering kali menjadi pemicu churn (seperti masalah dengan layanan atau pengalaman pelanggan negatif).
     
* Proporsi missing values ini sangat kecil dibandingkan total data (11 dari 7043), yaitu sekitar 0.16%

**Conclusion**: 11 data ini bisa di-drop karena tidak berkontribusi signifikan untuk model.
"""

# drop missing values
df = df.dropna(subset=['totalcharges'])

"""drop kolom yang tidak digunakan untuk kepentingan eda agar tidak mengganggu proses visualisasi data

#### **Drop Column**
"""

df = df.drop(columns='customerid', axis=1)

"""# **Exploratory Data Analysis**

menggunakan data yang merupakan hasil copy untuk di-transform sehingga data asli tetap terjaga keoriginalannya
"""

eda_df = df.copy()

"""#### **Univariate Analysis**:

Univariate analysis dengan data kategorik:
"""

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

categorical_columns = eda_df.select_dtypes(include=['object', 'category']).columns

def analyze_categorical(df: pd.DataFrame, categorical_columns):
    """Plots data kategorik dalam sebuah grid layout."""

    n_features = len(categorical_columns)
    n_rows = (n_features + 6 - 1) // 6
    fig, axes = plt.subplots(n_rows, 6, figsize=(20, 5 * n_rows), constrained_layout=True)

    axes = axes.flatten()
    for i, feature in enumerate(categorical_columns):
        ax = axes[i]
        sns.countplot(
            x=feature,
            data=df,
            palette="crest",
            order=df[feature].value_counts().index,
            ax=ax
        )
        ax.set_title(f"Distribution of {feature}")
        ax.set_xlabel("")
        ax.set_ylabel("Count")
        ax.tick_params(axis='x', rotation=45)

    # kosongkan axes yang tidak terpakai
    for i in range(n_features, len(axes)):
        fig.delaxes(axes[i])

    plt.show()

analyze_categorical(eda_df, categorical_columns)

"""**Insights**:

* **Personal informations**:
    * `gender` -> Tidak terdapat perbedaan yang signifikan antara data female dengan male.
    * `seniorcitizen` -> Terdapat perbedaan yang signifikan, jumlah data di kelompok 0 jauh lebih banyak yang artinya pelanggan didominasi oleh warga non-lansia.
    * `partner` -> Perbedaan tidak terlalu jauh, tetapi didominasi oleh pelanggan yang tidak memiliki pasangan.
    * `dependents` -> Didominasi oleh pelanggan yang tidak memiliki tanggungan atau tinggal sendiri.

* **Services**:
    * `phoneservice` -> Terdapat perbedaan yang sangat signifikan dan didominasi oleh pelanggan yang berlangganan layanan telepon (mungkin berupa telepon rumah atau ponsel).
    * `multiplelines` -> Didominasi oleh pelanggan yang hanya memiliki satu saluran telepon, lalu diikuti oleh pelanggan yang berlangganan dengan lebih dari satu saluran telepon atau kelompok `no`.
    * `internetservice` -> Terdapat perbedaan yang cukup jauh antara penggunaan fiber optic, dsl, dan tidak menggunakan sama sekali. Ini berarti banyak pelanggan yang menggunakan layanan fiber optic untuk layanan internetnya.
    * `onlinesecurity`, `onlinebackup`, `deviceprotection`, `techsupport`, `streamingtv`, `streamingmovies` -> Untuk layanan tambahan atau add-on pelanggan kebanyakan tidak memilih untuk berlangganan pada layanan ini, tetapi pada layanan `streamingtv` dan `streamingmovies` perbedaan cukup tipis yang menandakan jumlah pelanggan yang berlangganan maupun tidak perbedaannya tidak signifikan, tapi masih didominasi oleh pelanggan yang tidak berlangganan, lalu diikuti oleh pelanggan yang berlangganan, dan tidak memiliki layanan internet sama sekali.

* **System and payment**:
    * `contract` -> Banyak pelanggan yang memilih sistem kontrak month-to-month dibandingkan dua sistem kontrak lainnya, yaitu two year dan one year.
    * `paperlessbilling` -> Didominasi oleh pelanggan yang memilih penagihan tanpa kertas (paperless). Tagihan ini biasanya dikirim melalui email atau portal online, dan pembayaran biasanya dilakukan menggunakan metode elektronik.
    * `paymentmethod` -> Terdapat perbedaan yang signifikan antara electronic check dengan tiga metode pembayaran lainnya, yang menandakan bahwa pelanggan lebih memilih menggunakan electronic check.

* **Churn**:
    * `churn` -> Terdapat perbedaan yang sangat signifikan antara pelanggan yang akan churn dan tidak, data didominasi oleh pelanggan yang tidak churn.

Univariate analysis dengan data numerik:
"""

numerical_columns = eda_df.select_dtypes(exclude=['object', 'category']).columns

def analyze_numerical(df: pd.DataFrame, features):
     """Plots distribusi data numerik."""

     n_cols = 3
     n_rows = (3 + n_cols - 1) // n_cols
     plt.figure(figsize=(15, 5 * n_rows))

     for i, feature in enumerate(features):
        plt.subplot(n_rows, n_cols, i + 1)
        sns.histplot(df[feature], kde=True, bins=30)
        mean_val = df[feature].mean()
        plt.axvline(mean_val, color='r', linestyle='dashed', linewidth=1)
        plt.text(mean_val * 1.01, plt.ylim()[1] * 0.9, f'μ = {mean_val:.2f}', color='r')
        plt.title(f"Distribution of {feature}")
        plt.xlabel(feature)
        plt.ylabel("Count")

     plt.tight_layout()
     plt.show()

analyze_numerical(eda_df, numerical_columns)

"""**Insights**:
* Tidak ada kolom yang berdistribusi normal atau simetris.
* `tenure` distribusinya nyaris seperti distribusi U (U-shaped distribution) dan distribusinya terbagi menjadi 2 populasi dengan perilaku berbeda, seperti pola awal didominasi pelanggan baru dan pola akhir diisi oleh pelanggan yang loyal dan jarang ada nilai di tengah, mean-nya juga nyaris mendekati median.
* `monthlycharges` menunjukkan distribusi yang sangat bervariasi dan terlihat data terkonsentrasi di sekitar `$70` sampai `$90`.
* `totalcharges` terlihat seperti distribusi log-normal atau positively skewed (right-skewed) dimana mean > median dan mayoritas datanya terdapat di sekitar `$0 - $100`, semakin kecil di bagian kanan (tail) mengindikasikan harga yang semakin mahal dan hal ini logis karena semakin mahal harganya maka belum tentu semua orang sanggup.
* Nilai besar di ekor (tail) distribusi right-skewed tetap perlu diperhatikan karena bisa saja memengaruhi model.
* Transformasi data atau scaling bisa menjadi solusi untuk mengurangi dampak distribusi yang tidak seimbang.
"""

eda_df.describe()

"""**Insights**:
* Data `totalcharges` memiliki rentang yang sangat besar yaitu dengan `min = 18.8` dan `max = 8684.8`, dengan kuartil 1 `(Q1) = 401.45`, `Q2 = 1397.475`, dan `Q3 = 3794.7375` menunjukkan selisih antar kuartil cukup besar.
* Mengingat selisihnya yang besar dan Q3 cukup tinggi yaitu 3794.74, membuat kemungkinan bahwa nilai `max = 8684.8` bukanlah outlier karena batas deteksi outlier di atas `Q3 + 1.5 x IQR` bisa sangat jauh sehingga nilai disekitar max masih ada di dalam rentang.
"""

def boxplot(numerical_columns: list):
    """Membuat boxplot data numerik"""

    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False)
    for i, feature in enumerate(numerical_columns):
        sns.boxplot(data=eda_df, y=feature, ax=axes[i])
        axes[i].set_title(f"Boxplot of {feature}")
        axes[i].set_ylabel("Value")
    plt.tight_layout()
    plt.show()

boxplot(numerical_columns)

"""**Insight**:
* Tidak ada outlier di semua data numerik sehingga tidak perlu menangani outlier.

#### **Bivariate Analysis**:

Analisis bivariat antara data kategorik dan kategorik menggunakan barchart.
"""

def bivariate_analysis_barchart(df: pd.DataFrame, churn_col: str, categorical_columns):
    """Membuat barcharts untuk menganalisis hubungan antara data kategorik dengan target."""

    if churn_col in categorical_columns:
        categorical_columns = [col for col in categorical_columns if col != churn_col]

    num_cols = 4
    num_rows = (len(categorical_columns) // num_cols) + (1 if len(categorical_columns) % num_cols != 0 else 0)
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 6 * num_rows))
    axes = axes.flatten()

    for i, col in enumerate(categorical_columns):
        churn_distribution = df.groupby([churn_col, col]).size().reset_index(name='count')
        sns.barplot(data=churn_distribution, x=col, y='count', hue=churn_col, palette='coolwarm', ax=axes[i])
        axes[i].set_title(f'{col} vs {churn_col}', fontsize=14)
        axes[i].set_ylabel('Count')
        axes[i].set_xlabel('')
        axes[i].tick_params(axis='x', rotation=45)

        # membuat legend
        handles, labels = axes[i].get_legend_handles_labels()
        axes[i].legend(handles=handles, labels=['Not Churn', 'Churn'], title='Churn', loc='upper right')

    # hapus subplots yang tidak digunakan
    for j in range(len(categorical_columns), len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

bivariate_analysis_barchart(eda_df, churn_col='churn', categorical_columns=categorical_columns[:4])

"""**Insights**:
* `gender` -> Pada gender female perbedaan pelanggan yang churn dan tidak churn sangat signifikan dan hal yang sama terjadi pada gender male juga. Namun, jika kedua gender dibandingkan outputnya terlihat cukup mirip atau sama.
* `seniorcitizen` -> Terdapat perbedaan signifikan antara pelanggan yang churn dan tidak churn pada kelompok pelanggan yang bukan lansia atau `0`, di mana pelanggan yang tidak churn cenderung lebih dominan. Sebaliknya, pada kelompok pelanggan lansia, pola yang berbeda terlihat, di mana jumlah pelanggan yang churn melebihi 50% dari pelanggan lansia yang tidak churn.
* `partner` -> Jika hanya membandingkan jumlah pelanggan churn-nya saja, terlihat bahwa pelanggan yang tidak memiliki pasangan kecenderungan untuk churn-nya jauh lebih tinggi dibandingkan pelanggan yang memiliki pasangan padahal pelanggan yang memiliki pasangan jumlahnya lebih banyak.
* `dependents` -> Jika hanya membandingkan jumlah pelanggan churn-nya, terlihat bahwa pelanggan yang tidak memiliki tanggungan memiliki kecenderungan untuk churn lebih tinggi dibandingkan pelanggan yang memiliki tanggungan.
"""

bivariate_analysis_barchart(eda_df, churn_col='churn', categorical_columns=categorical_columns[4:8])

"""**Insights**:
* `phoneservice` -> Ketika berfokus pada pelanggan yang churn saja, terlihat bahwa pelanggan yang berlangganan pada layanan phoneservice lebih banyak memiliki kecenderungan untuk churn dibandingkan pelanggan yang tidak berlangganan. Hal ini bisa menjadi indikator akan adanya ketidakpuasan akan layanan phoneservice yang diberikan.
* `multiplelines` -> Pada multiplelines pelanggan yang hanya berlangganan pada satu saluran atau di kelompok `no` dan berlangganan dengan multiplelines (kelompok `yes`) memiliki jumlah churn yang sama. Ini bisa menjadi indikasi bahwa adanya ketidakpuasan akan layanan yang diberikan.
* `internetservice` -> Jumlah pelanggan churn di kelompok fiber optic telah melebihi 50% dari jumlah pelanggan yang tidak churn di kelompok tersebut, hal ini bisa mengindikasikan ada yang salah sehingga mempengaruhi kepuasan pelanggan dan perlu dioptimalisasi.
* `onlinesecurity` -> Pada layanan add-on atau tambahan ini, jumlah pelanggan churn pada kelompok tidak berlangganan telah melebihi 50% dari pelanggan yang tidak churn di kelompok ini. Hal ini mengindikasikan jika pelanggan tidak berlangganan pada layanan tambahan maka memiliki tendensi untuk churn.
"""

bivariate_analysis_barchart(eda_df, churn_col='churn', categorical_columns=categorical_columns[8:12])

"""**Insights**:
* `onlinebackup`, `deviceprotection`, `techsupport` -> Jumlah pelanggan yang churn pada kelompok tidak berlangganan atau `no` lebih banyak dan melebihi 50% dari pelanggan yang tidak churn di kelompok ini, ini mengindikasikan jika pelanggan tidak berlangganan pada layanan tambahan yang tertera maka memiliki kecenderungan churn lebih tinggi.
* `streamingtv` -> Pelanggan yang churn di kelompok tidak berlangganan dan berlangganan layanan ini jumlahnya mirip atau perbedaan antar pelanggan yang churn di kelompok `no` dan `yes` tidak signifikan.
"""

bivariate_analysis_barchart(eda_df, churn_col='churn', categorical_columns=categorical_columns[12:])

"""**Insights**:
* `streamingmovies` -> Pada kelompok tidak berlangganan atau `no` terlihat bahwa churn jumlahnya memenuhi 50% dari pelanggan yang tidak churn. Kemudian, pada kelompok `yes` pelanggan memiliki kecenderungan churn yang cukup tinggi juga. Ini mengindikasikan adanya ketidakpuasan atas layanan yang diberikan.
* `contract` -> Pelanggan pada kelompok `month-to-month` memiliki kecenderungan yang lebih tinggi untuk churn dan itu ditunjukkan dengan bar chart yang jumlahnya melebihi 50% dari jumlah pelanggan yang tidak churn.
* `paperlessbilling` -> Pelanggan pada kelompok `yes` memiliki kecenderungan churn jauh lebih banyak daripada kelompok `no`, ini bisa menjadi indikator adanya ketidakpuasan pelanggan atas layanan yang diberikan.
* `paymentmethod` -> Terlihat pelanggan yang churn mendominasi kelompok `electornic check` yang mengindikasikan adanya ketidakpuasan layanan pembayaran dengan metode ini.
"""

def boxplot_churn(df: pd.DataFrame, numerical_columns, churn_col: str):
    """Membuat boxplot untuk menganalisis hubungan data numerik dengan target."""

    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    for i, col in enumerate(numerical_columns[:3]):
        sns.boxplot(data=df, x=churn_col, y=col, palette='coolwarm', ax=axes[i])
        axes[i].set_title(f'{col} distribution by {churn_col}', fontsize=14)
        axes[i].set_ylabel(col)
        axes[i].set_xlabel('')
        axes[i].set_xticks([0, 1])
        axes[i].set_xticklabels(['Not Churn', 'Churn'])
    plt.tight_layout()
    plt.show()

boxplot_churn(eda_df, numerical_columns, churn_col='churn')

"""**Insights**:
* `tenure`:
     * Pada kelompok pelanggan yang tidak churn terdapat dari range 0 hingga 70 bulan dan rata-rata berlangganan sekitar 37 bulan.
     * Pada kelompok pelanggan yang churn terdapat dari range 0 hingga 68 bulan dan nilai di atas ini sudah dianggap outlier atau pencilan. Rata-rata pelanggan yang churn berlangganan kira-kira 9 bulan.
* `monthlycharges`:
     * Pada kelompok tidak churn rata-rata pelanggan memiliki tagihan bulanan sekitar `$63`.
     * Pada kelompok pelanggan yang churn, rata-rata tagihan bulanannya adalah `$80`.
* `totalcharges`:
     * Di kelompok tidak churn rata-rata pelanggan memiliki tagihan sekitar `$1700`.
     * Di kelompok churn rata-rata tagihan pelanggan sekitar `$600`.

#### **Multivariate Analysis**:

Melakukan encoding menggunakan label encoder pada data kategorikal agar mempermudah proses visualisasi dan pemprosesan oleh algoritma machine learning.


* Menggunakan label encoder karena dataset memiliki beberapa data kategorik, dengan menggunakan ini daripada ohe maka    proses encoding tidak menambah dimensi dataset, serta saya menggunakan algoritma machine learning yang tidak memperhatikan urutan data.
"""

for col in categorical_columns:
    le = LabelEncoder()
    eda_df[col] = le.fit_transform(eda_df[col])

def generate_correlation_heatmap(df: pd.DataFrame):
    """Membuat heatmap korelasi dari dataframe."""

    plt.figure(figsize=(12, 10))
    sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5)
    plt.title("Correlation Heatmap")
    plt.show()

def generate_pairplot(numerical_columns):
    """Membuat pairplot data numerik dari dataframe."""

    numerical_df = df[numerical_columns]
    sns.pairplot(numerical_df)
    plt.suptitle("Pair Plot of Features", y=1.02)
    plt.show()

generate_correlation_heatmap(eda_df)

"""**Insight**:

* Semakin lama pelanggan berlangganan, semakin rendah kecenderungannya untuk churn, menunjukkan hubungan negatif yang kuat antara durasi berlangganan dan churn. Di sisi lain, durasi berlangganan yang lebih lama juga terkait dengan nilai kontrak yang lebih tinggi, menunjukkan hubungan positif antara keduanya. Selain itu, pelanggan yang memilih layanan tambahan atau add-on juga cenderung memiliki durasi berlangganan yang lebih lama, mengindikasikan bahwa keputusan untuk menambah layanan memperpanjang hubungan mereka dengan penyedia.

membuat pairplot berdasarkan data numerik:
"""

generate_pairplot(numerical_columns)

"""**Insights**:
* Terdapat pola atau trend linear antara `tenure` dengan `totalcharges` dan `monthlycharges` dengan `totalcharges` yang menandakan korelasi positif atau ketika tenure meningkat maka totalcharges juga akan ikut meningkat, begitu pula dengan hubungan antara monthlycharges dan totalcharges.
* Pola data yang membentuk segitiga di bawah atau di atas garis linear disebabkan oleh distribusi data yang tidak normal dan tingkat variasi data yang tinggi. Variasi ini membuat data tampak menyebar dalam pola yang menyerupai segitiga di scatter plot.

# **Data Preparation**

#### **Feature Selection**

Dataset memiliki 19 features dan memungkinkan bahwa kolom-kolom memiliki nilai atau noise yang tidak diperlukan sehingga akan mempengaruhi output model nantinya. Feature selection dilakukan untuk memilih features yang relevan dan sangat berkaitan dengan target atau customer churn. Uji independensi chi-square, digunakan untuk menguji apakah dua variabel kategorik (feature dan target) berhubungan satu sama lain atau mempengaruhi y (target).

##### **Categorical Encoding**

Menggunakan label encoding daripada one-hot encoding (OHE) karena jumlah nilai unik pada kolom kategorikal ada sebanyak 4. Label encoding dapat menghindari peningkatan dimensi yang besar, yang sering terjadi pada OHE lalu label encoding lebih efisien dalam hal komputasi dan memori. Karena kategori terbatas dan algoritma yang saya gunakan tidak sensitif terhadap skala atau urutan numerik, penggunaan label encoding dapat mempercepat proses pelatihan tanpa menurunkan performa model.
"""

# encoding data kategorik
df_categoric = df[categorical_columns].copy()

for col in categorical_columns:
    le = LabelEncoder()
    df_categoric[col] = le.fit_transform(df_categoric[col])

# menentukan features dan target
X = df_categoric.iloc[:, :-1]
y = df_categoric.iloc[:, -1]

# menerapkan class SelectKBest dengan chi2 untuk mengekstrak top 10 features
bestfeatures = SelectKBest(score_func=chi2, k=10)
fit = bestfeatures.fit(X, y)

dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)

# menggabungkan 2 dataframe untuk visualisasi
featureScores = pd.concat([dfscores, dfcolumns], axis=1)
featureScores.columns = ['Score', 'Feature']

print(featureScores.nlargest(10, 'Score'))

"""**Insights**:
* Semakin tinggi nilai score berarti feature tersebut memiliki hubungan yang lebih kuat atau lebih relevan dengan target (y).
* Sebaliknya jika nilai score rendah, berarti feature memiliki hubungan yang lebih lemah bahkan kurang relevan dengan target (y).

**Conclusion**: 10 features yang berasal dari hasil uji chi-square inilah yang digunakan untuk proses modeling.

ANOVA F-value digunakan untuk mengetahui hubungan antara variabel numerik (feature) dengan variabel kategorik (target).
"""

df_numeric = df[numerical_columns].copy()

# membuat features dan target
X = df_numeric.iloc[:, :]
y = df_categoric.iloc[:, -1]

# menerapkan anova untuk mengekstrak top 3 features
bestfeatures = SelectKBest(score_func=f_classif, k=3)
fit = bestfeatures.fit(X, y)

dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)

# menggabungkan 2 dataframe untuk visualisasi
featureScores = pd.concat([dfscores, dfcolumns], axis=1)
featureScores.columns = ['Score', 'Feature']

print(featureScores.nlargest(3, 'Score'))

"""**Conclusion**: Berdasarkan hasil analisis ANOVA, semua data numerik atau features yang dianalisis menunjukkan kontribusi yang kuat. Di antara fitur-fitur tersebut, tenure berada di peringkat teratas, menandakan bahwa fitur ini memiliki hubungan paling kuat dan sangat relevan dengan target.

#### **Merge Data and Drop Unselected Features**

Drop kolom yang tidak memiliki pengaruh yang signifikan atau tidak terpilih saat feature selection untuk mengurangi dimensi data, meningkatkan efisiensi model, dan menghindari overfitting atau noise.
"""

columns_to_drop = ['multiplelines', 'internetservice', 'streamingmovies', 'streamingtv', 'gender', 'phoneservice']

# membuat dataframe dengan features yang dipilih
df = pd.concat([df_categoric, df_numeric], axis=1)
df.drop(columns = columns_to_drop, axis=1, inplace=True)

df.head().T

"""#### **Train Test Data Split**

Melakukan splitting dataset:
* Test size 0.2 berarti 20% dari dataset digunakan untuk data testing, sementara 80% digunakan untuk data training.
* Data training (80%) digunakan untuk mengumpulkan sebanyak mungkin informasi dari dataset guna melatih model secara optimal.
* Random state memastikan bahwa setiap kali proses splitting dataset dilakukan ulang, hasil pembagian data tetap konsisten.
"""

# splitting features dan target
X = df.drop(columns='churn')
y = df['churn']

# splitting training dan testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Training features: {X_train.shape}')
print(f'Training target: {y_train.shape}')
print(f'Testing features: {X_test.shape}')
print(f'Testing target: {y_test.shape}')

X_train.head().T

# visualisasi training dan testing data
plt.figure(figsize=(8, 6))
plt.scatter(X_train.index, X_train['totalcharges'], color='blue', alpha=0.6, label='Training Data')
plt.scatter(X_test.index, X_test['totalcharges'], color='orange', alpha=0.6, label='Testing Data')
plt.title("Scatter Plot of Training and Testing Data")
plt.xlabel("Index")
plt.ylabel("Total Charges")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

"""**Insight**:
* `index` -> representasi urutan data
* Visualisasi scatter plot ini menggunakan nomer index sebagai sumbu x dan total charges sebagai sumbu y untuk menunjukkan function `train_test_split` secara default men-shuffle dataset. Tujuan data training dan testing diacak adalah agar model tidak menghafal urutan data. Jika data tidak di-shuffle, model mungkin belajar pola yang tidak relevan berdasarkan urutan data, yang dapat menyebabkan bias dalam prediksi. Sehingga shuffling data penting, agar model yang dibuat menjadi general dan fokus pada pola tanpa dipengaruhi susunan atau urutan data dan juga model bisa belajar lebih efektif.
"""

# menunjukkan imbalance data
print(y_train.value_counts())
y_train.value_counts().plot.pie(autopct='%.2f')

"""**Insights**:
* Terdapat perbedaan yang signifikan antara pelanggan yang churn dan tidak, ini menandakan terjadinya imbalance dataset.
* Dari pie chart terlihat bahwa pelanggan yang tidak churn melebihi 50% atau hampir 3x lebih banyak dibandingkan pelanggan yang churn, rasio ketidakseimbangannya hampir 1:3.
* Imbalance data akan mempengaruhi performa model dalam prediksi, akurasi, dan generalisasi.

#### **Data Balancing**
"""

X_train.shape

"""Karena ukuran dataset yang relatif kecil dan model memerlukan banyak informasi, oversampling dengan teknik SMOTE digunakan untuk menghindari hilangnya informasi penting dari kelompok mayoritas (`not churn`). Proses ini dilakukan setelah train-test split, di mana hanya training set yang di-oversample agar data menjadi seimbang saat pelatihan, sementara testing set tetap dalam distribusi aslinya."""

# inisialisasi SMOTE
smote = SMOTE(random_state=42)

# fit dan resample data training
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("Distribusi data asli:", y_train.value_counts())
print('-' * 40)
print("Distribusi data resampling:", y_train_resampled.value_counts())

"""# **Modeling**

#### **Make List of Model**
"""

models = [
    XGBClassifier(random_state=42),
    LGBMClassifier(random_state=42, verbose=-1)
]

"""#### **Cross Validation**

Melakukan cross validation untuk screening awal atau mengetahui gambaran kasar performa model.
"""

def compare_models_cross_validation():
     """Membandingkan cross validation model dengan algoritma yang berbeda."""

     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
     for model in models:
          cv_score = cross_val_score(model, X_train_resampled, y_train_resampled, cv=skf, scoring='roc_auc')
          mean_accuracy = cv_score.mean()
          mean_accuracy = round(mean_accuracy, 4) * 100
          print(f'Cross Validation Score of {model.__class__.__name__}:\n {cv_score}')
          print()
          print(f'Mean score = {mean_accuracy:.2f}%')
          print('-' * 100)

compare_models_cross_validation()

"""**Insights**:
* Dengan membagi dataset menjadi 5 fold, setiap bagian akan menjadi test set satu kali.
* Tujuan dari cross validation adalah untuk mengetahui performa model secara lebih reliabel dan mengurangi risiko bias evaluasi dengan menguji performa pada semua fold, memastikan distribusi kelas tetap seimbang di setiap fold, dan memberikan estimasi yang lebih stabil.
* Karena dataset ini merupakan classification problem dengan imbalance data, maka digunakan `scoring='roc_auc'` dalam perhitungan cross-validation (CV) score. Metode ini dipilih karena ROC AUC lebih efektif dalam mengevaluasi model pada dataset yang tidak seimbang dan menilai kemampuan model dalam membedakan kelas positif dan negatif tanpa bergantung pada threshold, yang sangat berguna ketika data imbalanced dibandingkan metrik lain seperti akurasi.
* LGBMClassifier memiliki mean score yang sedikit lebih tinggi, yaitu `91.98%`, dibandingkan dengan XGBClassifier yang mencapai `91.92%`. Meskipun selisihnya hanya `0.06%`, perbedaan ini cukup signifikan karena dievaluasi menggunakan 5 fold cross validation. Hal ini menunjukkan bahwa LGBMClassifier secara konsisten memberikan performa yang lebih baik dibandingkan XGBClassifier.

#### **Compare Model Based on Metrics in Classification Report:**
"""

def compare_models():
    """Membandingkan performa model dengan algoritma yang berbeda menggunakan ROC AUC."""

    for model in models:
        model.fit(X_train_resampled, y_train_resampled)
        y_test_pred = model.predict(X_test)
        y_test_pred_proba = model.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test, y_test_pred_proba) * 100
        print(f'{model.__class__.__name__}:')
        print(f'ROC AUC score = {roc_auc:.2f}%')
        print(f'Confusion matrix:\n{confusion_matrix(y_test, y_test_pred)}\n')
        print(f'Classification report:\n{classification_report(y_test, y_test_pred)}')
        print('-' * 100)

def plot_confusion_matrices():
    """Menampilkan confusion matrix dengan heatmap untuk dua model."""

    confusion_matrices = []
    for model in models:
        model.fit(X_train_resampled, y_train_resampled)
        y_test_pred = model.predict(X_test)
        confusion_matrix_model = confusion_matrix(y_test, y_test_pred)
        confusion_matrices.append(confusion_matrix_model)

    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    for idx, matrix in enumerate(confusion_matrices):
        sns.heatmap(matrix, annot=True, fmt="d", cmap='Blues', ax=axes[idx])
        axes[idx].set_title(f'Confusion Matrix: {models[idx].__class__.__name__}')
        axes[idx].set_xlabel('Predicted')
        axes[idx].set_ylabel('True')
    plt.tight_layout()
    plt.show()

compare_models()

plot_confusion_matrices()

"""**Insights**:
* Meskipun ROC AUC score dari LGBMClassifier (81.89%) sedikit lebih tinggi dibandingkan XGBClassifier (80.85%), perbedaan ini sangat kecil, menunjukkan bahwa keduanya memiliki performa yang hampir sama. Namun, dalam hal confusion matrix, LGBMClassifier lebih unggul dalam memprediksi churn (kelompok 1), dengan 226 pelanggan churn yang diprediksi dengan benar, dibandingkan 214 pada model XGBoost. Ini berarti LGBMClassifier sedikit lebih efektif dalam mendeteksi pelanggan dengan kecenderungan churn.
* Data testing tidak seimbang (imbalance), evaluasi model sebaiknya tidak hanya berdasarkan accuracy, karena dapat memberikan gambaran yang menyesatkan. Dalam kasus ini, lebih baik fokus pada recall dan precision untuk kelas 1 (pelanggan churn), karena lebih baik untuk meminimalkan kesalahan dalam memprediksi pelanggan yang akan churn.
* Berdasarkan classification report, LGBMClassifier memiliki recall yang sedikit lebih tinggi (0.60 vs. 0.57) untuk kelompok churn, yang berarti lebih baik dalam menangkap pelanggan yang akan churn. Meskipun precision untuk kedua model mirip, recall pada LGBMClassifier menunjukkan bahwa model ini lebih sensitif dalam memprediksi pelanggan churn.
"""

def plot_roc_curves():
    """Memplot kurva ROC untuk membandingkan performa model berdasarkan ROC AUC."""

    plt.figure(figsize=(8, 6))
    for model in models:
        model.fit(X_train_resampled, y_train_resampled)
        y_test_pred_proba = model.predict_proba(X_test)[:, 1]

        # menghitung false positive rate (FPR) dan true positive rate (TPR)
        fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)
        roc_auc = roc_auc_score(y_test, y_test_pred_proba)

        plt.plot(fpr, tpr, lw=2, label=f'{model.__class__.__name__} (AUC = {roc_auc:.2f})')

    # garis diagonal sebagai baseline
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Classifier')

    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc='lower right')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

plot_roc_curves()

"""**Insights:**
* Di bagian awal kurva (false positive rate rendah), kedua model memiliki kemiringan yang mirip tetapi seiring meningkatnya rate kurva LGBMClassifier sedikit lebih tinggi daripada XGBClassifier dalam sebagian besar titik, itu berarti LGBMClassifier lebih efektif dalam menangkap pelanggan churn.
* LGBMClassifier memiliki area yang sedikit lebih besar di bawah kurva (AUC) dibandingkan XGBClassifier. Ini mengindikasikan bahwa secara keseluruhan, LGBMClassifier memiliki kecenderungan yang lebih kuat untuk memberi skor lebih tinggi pada pelanggan yang churn, menunjukkan bahwa model ini lebih mampu membedakan antara pelanggan yang churn dan tidak churn.

**Conclusion:** Berdasarkan cross validation score, ROC AUC, classification report maka model yang terbaik adalah LGBMClassifier, karena performanya lebih baik dan lebih seimbang dalam mendeteksi pelanggan churn, serta selinier dengan tujuan utama, yaitu mengidentifikasi untuk mempertahankan pelanggan yang memiliki risiko tinggi untuk churn.

#### **Chosen Model**
"""

lgbm_model = LGBMClassifier(random_state=42, verbose=-1)

"""#### **Hyperparameter Tuning**"""

param_grid = {
    'learning_rate': [0.01],
    'n_estimators': [1000],
    'max_depth': [5, 6, 7],
    'scale_pos_weight': [1, 2, 3]
}

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
grid_search = GridSearchCV(
    estimator=lgbm_model,
    param_grid=param_grid,
    scoring='roc_auc',
    cv=skf,
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_resampled, y_train_resampled)
print(f"Best Parameters: {grid_search.best_params_}")
best_model = grid_search.best_estimator_
y_pred_proba = best_model.predict_proba(X_test)[:, 1]
y_pred = (y_pred_proba >= 0.4).astype(int)

"""#### **Model Evaluation**

Menggunakan confusion matrix, ROC AUC score, dan classification report untuk evaluasi kinerja model.
"""

print(f'Confusion matrix:\n{confusion_matrix(y_test, y_pred)}\n')
roc_auc = roc_auc_score(y_test, y_pred_proba) * 100
print(f'ROC AUC score = {roc_auc:.2f}%')
print(f'Classification report:\n{classification_report(y_test, y_pred)}')

"""**Insights:**
* Menurunkan threshold agar bisa mendeteksi pelanggan dengan kecenderungan churn lebih efektif.
* Model yang telah melalui hyperparameter tuning memiliki ROC AUC score yang sedikit lebih tinggi `82,25%` dibandingkan sebelumnya, `81,89%`. Selain itu, recall untuk model kedua lebih baik (0,71 dibandingkan dengan 0,60), yang berarti model ini lebih efektif dalam menangkap pelanggan yang berpotensi churn. Dalam konteks bisnis, sangat penting untuk mengidentifikasi pelanggan yang mungkin akan berhenti menggunakan layanan, sehingga perusahaan dapat mengambil tindakan pencegahan yang lebih cepat dan mempertahankan pelanggan yang ada.
* Dengan demikian, pelanggan yang berpotensi churn dapat terdeteksi sehingga memberikan peluang lebih banyak bagi tim retensi untuk mengintervensi dan menyelamatkan pelanggan yang hampir meninggalkan layanan, sehingga kepuasan dan loyalitas pelanggan dapat ditingkatkan.
"""